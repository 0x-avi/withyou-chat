{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9e17f56",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m therapist = Therapist(memory=memory)\n\u001b[32m     39\u001b[39m therapist.memory_tools.set_user_id(\u001b[33m'\u001b[39m\u001b[33maviral\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m therapist.acall(\u001b[33m'\u001b[39m\u001b[33mmy name is aviral\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/withyou-chat/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:296\u001b[39m, in \u001b[36mwith_callbacks.<locals>.async_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m callbacks = _get_active_callbacks(instance)\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(instance, *args, **kwargs)\n\u001b[32m    298\u001b[39m call_id = uuid.uuid4().hex\n\u001b[32m    300\u001b[39m _execute_start_callbacks(instance, fn, call_id, callbacks, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/withyou-chat/.venv/lib/python3.12/site-packages/dspy/primitives/module.py:93\u001b[39m, in \u001b[36mModule.acall\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m         output.set_lm_usage(usage_tracker.get_total_tokens())\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aforward(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/withyou-chat/Agent.py:26\u001b[39m, in \u001b[36mTherapist.aforward\u001b[39m\u001b[34m(self, user_input)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_input: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     25\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Process user input with memory-aware reasoning.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     retrieved_memories = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.memory_tools.search_for_memories(user_input)\n\u001b[32m     27\u001b[39m     task = \u001b[38;5;28mself\u001b[39m.memory_tools.add_memory(user_input)\n\u001b[32m     28\u001b[39m     pred =  \u001b[38;5;28mself\u001b[39m.pred(user_input=\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretrieved_memories\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/withyou-chat/Memory.py:15\u001b[39m, in \u001b[36mMemOps.search_for_memories\u001b[39m\u001b[34m(self, query)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch_for_memories\u001b[39m(\u001b[38;5;28mself\u001b[39m,query : \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     memories = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\u001b[38;5;28mself\u001b[39m.memory.search(query=query,limit=\u001b[32m1\u001b[39m,user_id=\u001b[38;5;28mself\u001b[39m.user_id))\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mretrieved all memory\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m     memory_text = \u001b[33m\"\u001b[39m\u001b[33mHere are all memories for user:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/withyou-chat/.venv/lib/python3.12/site-packages/mem0/memory/main.py:1534\u001b[39m, in \u001b[36mAsyncMemory.search\u001b[39m\u001b[34m(self, query, user_id, agent_id, run_id, limit, filters, threshold)\u001b[39m\n\u001b[32m   1532\u001b[39m     original_memories, graph_entities = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(vector_store_task, graph_task)\n\u001b[32m   1533\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1534\u001b[39m     original_memories = \u001b[38;5;28;01mawait\u001b[39;00m vector_store_task\n\u001b[32m   1535\u001b[39m     graph_entities = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enable_graph:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/repos/withyou-chat/.venv/lib/python3.12/site-packages/mem0/memory/main.py:1553\u001b[39m, in \u001b[36mAsyncMemory._search_vector_store\u001b[39m\u001b[34m(self, query, filters, limit, threshold)\u001b[39m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_search_vector_store\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, filters, limit, threshold: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     embeddings = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.to_thread(\u001b[38;5;28mself\u001b[39m.embedding_model.embed, query, \u001b[33m\"\u001b[39m\u001b[33msearch\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1554\u001b[39m     memories = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.to_thread(\n\u001b[32m   1555\u001b[39m         \u001b[38;5;28mself\u001b[39m.vector_store.search, query=query, vectors=embeddings, limit=limit, filters=filters\n\u001b[32m   1556\u001b[39m     )\n\u001b[32m   1558\u001b[39m     promoted_payload_keys = [\n\u001b[32m   1559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1560\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33magent_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1563\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1564\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-macos-aarch64-none/lib/python3.12/asyncio/threads.py:25\u001b[39m, in \u001b[36mto_thread\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m ctx = contextvars.copy_context()\n\u001b[32m     24\u001b[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from mem0 import AsyncMemory\n",
    "from Agent import Therapist\n",
    "import dspy\n",
    "import asyncio\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "config = {\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"qdrant\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"test\",\n",
    "            \"url\" : os.environ['QDRANT_URL'],\n",
    "            \"api_key\" : os.environ['QDRANT_API_KEY'],\n",
    "        }},\n",
    "    \"llm\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"gpt-5-nano-2025-08-07\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 2000,\n",
    "        }\n",
    "    } ,\n",
    "        \"embedder\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"text-embedding-3-small\"\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "\n",
    "memory = await AsyncMemory.from_config(config)\n",
    "\n",
    "lm = dspy.LM('openai/gpt-5-nano-2025-08-07',temperature=1.0,max_tokens=16000)\n",
    "dspy.configure(lm=lm)\n",
    "therapist = Therapist(memory=memory)\n",
    "therapist.memory_tools.set_user_id('aviral')\n",
    "print(await therapist.acall('my name is aviral'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5bdbd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'id': '22cd7489-a8af-4685-ad4e-4e9ef4814bf7',\n",
       "   'memory': 'i live in mumbai',\n",
       "   'hash': 'b9e95e296152060b8db8937ce32461cf',\n",
       "   'metadata': None,\n",
       "   'created_at': '2025-09-25T10:28:15.956415-07:00',\n",
       "   'updated_at': None,\n",
       "   'user_id': 'aviral',\n",
       "   'role': 'user'}]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await therapist.memory_tools.get_all_memories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69bd311c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aviral'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "therapist.memory_tools.get_user_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dfc0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = await therapist.memory_tools.search_for_memories('what was my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f74c143e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are all memories for user:\\n0. Name is aviral\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45ee1be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'memory_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmemory_text\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'memory_text' is not defined"
     ]
    }
   ],
   "source": [
    "memory_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c801c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "withyou-chat (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
